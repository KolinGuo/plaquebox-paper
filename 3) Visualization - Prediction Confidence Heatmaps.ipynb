{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Visualization - Prediction Confidence Heatmaps\n",
    "\n",
    "A sliding window approach was applied on the whole slide images (WSIs) with the trained CNN model to generate confidence heatmaps. \n",
    "\n",
    "The WSIs were tiled into 1536 x 1536 images patches in the prepocessing steps. A sliding window approached was applied on evey image patch of a WSI. At each time, the CNN model took a 256x256 pixels region as input, forward propagated and generated a prediction score for cored plaque, diffuse plaque and CAA respectively. By systematically sliding the input region across the entire 1536 x 1536 image patch, the prediction scores were saved and ploted as prediction confidence heatmap for this patch. The heatmap for the WSI was obtained by doing this on all image patches of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os, glob\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(123456789)\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIR  = 'data/norm_tiles/'\n",
    "MODEL_DIR = 'models/CNN_model_parameters.pkl'\n",
    "SAVE_DIR = 'data/outputs/heatmaps/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(SAVE_DIR):\n",
    "        os.makedirs(SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 1536\n",
    "stride = 16\n",
    "batch_size = 64\n",
    "num_workers = 16\n",
    "\n",
    "norm = np.load('utils/normalization.npy', allow_pickle=True).item()\n",
    "normalize = transforms.Normalize(norm['mean'], norm['std'])\n",
    "to_tensor = transforms.ToTensor()\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "filenames = glob.glob(IMG_DIR + '*')\n",
    "filenames = [filename.split('/')[-1] for filename in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class HeatmapDataset(Dataset):\n",
    "    def __init__(self, tile_dir, row, col, stride=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tile_dir (string): path to the folder where tiles are\n",
    "            row (int): row index of the tile being operated\n",
    "            col (int): column index of the tile being operated\n",
    "            stride: stride of sliding \n",
    "        \"\"\"\n",
    "        self.tile_size = 256\n",
    "        self.img_size = 1536\n",
    "        self.stride = stride\n",
    "        padding = 128\n",
    "        large_img = torch.ones(3, 3*self.img_size, 3*self.img_size)\n",
    "        \n",
    "        for i in [-1,0,1]:\n",
    "            for j in [-1,0,1]:\n",
    "                img_path = tile_dir+'/'+str(row+i)+'/'+str(col+j)+'.jpg'\n",
    "                try:\n",
    "                    img = Image.open(img_path)\n",
    "                    img = transforms.ToTensor()(img) \n",
    "                except:\n",
    "                    img = torch.ones(3,self.img_size, self.img_size)\n",
    "                \n",
    "                large_img[:, (i+1)*self.img_size:(i+2)*self.img_size,(j+1)*self.img_size:(j+2)*self.img_size] = img\n",
    "        \n",
    "        large_img = normalize(large_img)\n",
    "        \n",
    "        self.padding_img = large_img[:,self.img_size-padding:2*self.img_size+padding, self.img_size-padding:2*self.img_size+padding]\n",
    "        self.len = (self.img_size//self.stride)**2\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        row = (index*self.stride // self.img_size)*self.stride\n",
    "        col = (index*self.stride % self.img_size)\n",
    "\n",
    "        img = self.padding_img[:, row:row+self.tile_size, col:col+self.tile_size]        \n",
    "    \n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, fc_nodes=512, num_classes=3, dropout=0.5):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    " \n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instatiate the model\n",
    "model = torch.load(MODEL_DIR, map_location=lambda storage, loc: storage)\n",
    "\n",
    "if use_gpu:\n",
    "    model = model.module.cuda()\n",
    "else:\n",
    "    model = model.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in filenames:\n",
    "    TILE_DIR = IMG_DIR+'{}/0/'.format(filename)\n",
    "\n",
    "    imgs = []\n",
    "    for target in sorted(os.listdir(TILE_DIR)):\n",
    "        d = os.path.join(TILE_DIR, target)\n",
    "        if not os.path.isdir(d):\n",
    "            continue\n",
    "\n",
    "        for root, _, fnames in sorted(os.walk(d)):\n",
    "            for fname in sorted(fnames):\n",
    "                if fname.endswith('.jpg'):\n",
    "                    path = os.path.join(root, fname)\n",
    "                    imgs.append(path)\n",
    "\n",
    "    rows = [int(image.split('/')[-2]) for image in imgs]\n",
    "    row_nums = max(rows) + 1\n",
    "    cols = [int(image.split('/')[-1].split('.')[0]) for image in imgs]\n",
    "    col_nums = max(cols) +1    \n",
    "    \n",
    "    heatmap_res = img_size // stride\n",
    "    final_output = np.zeros((3, heatmap_res*row_nums, heatmap_res*col_nums))\n",
    "\n",
    "    model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "    for row in tqdm(range(row_nums)):\n",
    "        for col in range(col_nums):\n",
    "\n",
    "            image_datasets = HeatmapDataset(TILE_DIR, row, col, stride=stride)\n",
    "            dataloader = torch.utils.data.DataLoader(image_datasets, batch_size=batch_size,\n",
    "                                                 shuffle=False, num_workers=num_workers)\n",
    "\n",
    "            running_preds = torch.Tensor(0)\n",
    "            for data in dataloader:\n",
    "                # get the inputs\n",
    "                inputs = data\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    inputs = Variable(inputs.cuda(), volatile=True)\n",
    "                    # forward\n",
    "                    outputs = model(inputs)\n",
    "                    preds = F.sigmoid(outputs) #posibility for each class\n",
    "                    preds = preds.data.cpu()\n",
    "                    running_preds = torch.cat([running_preds, preds])\n",
    "\n",
    "            cored = np.asarray(running_preds[:,0]).reshape(img_size//stride,img_size//stride)\n",
    "            diffuse = np.asarray(running_preds[:,1]).reshape(img_size//stride,img_size//stride)\n",
    "            caa = np.asarray(running_preds[:,2]).reshape(img_size//stride,img_size//stride)\n",
    "\n",
    "            final_output[0, row*heatmap_res:(row+1)*heatmap_res, col*heatmap_res:(col+1)*heatmap_res] = cored\n",
    "            final_output[1, row*heatmap_res:(row+1)*heatmap_res, col*heatmap_res:(col+1)*heatmap_res] = diffuse\n",
    "            final_output[2, row*heatmap_res:(row+1)*heatmap_res, col*heatmap_res:(col+1)*heatmap_res] = caa\n",
    "\n",
    "    np.save(SAVE_DIR+filename, final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-bb311a7f43a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m311\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'viridis'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdivider\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_axes_locatable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdivider\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"right\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"5%\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_output' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3240x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(45,15))\n",
    "    \n",
    "ax = fig.add_subplot(311)\n",
    "\n",
    "im = ax.imshow(final_output[0], cmap=plt.cm.get_cmap('viridis', 20), vmin=0, vmax=1)\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "plt.colorbar(im, cax=cax, ticks=[0.0, 0.25, 0.5, 0.75, 1.0])\n",
    "\n",
    "ax = fig.add_subplot(312)\n",
    "\n",
    "im = ax.imshow(final_output[1], cmap=plt.cm.get_cmap('viridis', 20), vmin=0, vmax=1)\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "plt.colorbar(im, cax=cax, ticks=[0.0, 0.25, 0.5, 0.75, 1.0])\n",
    "\n",
    "ax = fig.add_subplot(313)\n",
    "\n",
    "im = ax.imshow(final_output[2], cmap=plt.cm.get_cmap('viridis', 20), vmin=0, vmax=1)\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "plt.colorbar(im, cax=cax, ticks=[0.0, 0.25, 0.5, 0.75, 1.0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
