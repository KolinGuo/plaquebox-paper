{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Visualization - Prediction Confidence Heatmaps\n",
    "\n",
    "A sliding window approach was applied on the whole slide images (WSIs) with the trained CNN model to generate confidence heatmaps. \n",
    "\n",
    "The WSIs were tiled into 1536 x 1536 images patches in the prepocessing steps. A sliding window approached was applied on evey image patch of a WSI. At each time, the CNN model took a 256x256 pixels region as input, forward propagated and generated a prediction score for cored plaque, diffuse plaque and CAA respectively. By systematically sliding the input region across the entire 1536 x 1536 image patch, the prediction scores were saved and ploted as prediction confidence heatmap for this patch. The heatmap for the WSI was obtained by doing this on all image patches of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os, glob\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(123456789)\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIR  = 'data/norm_tiles/'\n",
    "MODEL_DIR = 'models/CNN_model_parameters.pkl'\n",
    "SAVE_DIR = 'data/outputs/heatmaps/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(SAVE_DIR):\n",
    "        os.makedirs(SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 1536\n",
    "stride = 16\n",
    "batch_size = 64\n",
    "num_workers = 16\n",
    "\n",
    "norm = np.load('utils/normalization.npy', allow_pickle=True).item()\n",
    "normalize = transforms.Normalize(norm['mean'], norm['std'])\n",
    "to_tensor = transforms.ToTensor()\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "filenames = glob.glob(IMG_DIR + '*')\n",
    "filenames = [filename.split('/')[-1] for filename in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class HeatmapDataset(Dataset):\n",
    "    def __init__(self, tile_dir, row, col, stride=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tile_dir (string): path to the folder where tiles are\n",
    "            row (int): row index of the tile being operated\n",
    "            col (int): column index of the tile being operated\n",
    "            stride: stride of sliding \n",
    "        \"\"\"\n",
    "        self.tile_size = 256\n",
    "        self.img_size = 1536\n",
    "        self.stride = stride\n",
    "        padding = 128\n",
    "        large_img = torch.ones(3, 3*self.img_size, 3*self.img_size)\n",
    "        \n",
    "        for i in [-1,0,1]:\n",
    "            for j in [-1,0,1]:\n",
    "                img_path = tile_dir+'/'+str(row+i)+'/'+str(col+j)+'.jpg'\n",
    "                try:\n",
    "                    img = Image.open(img_path)\n",
    "                    img = transforms.ToTensor()(img) \n",
    "                except:\n",
    "                    img = torch.ones(3,self.img_size, self.img_size)\n",
    "                \n",
    "                large_img[:, (i+1)*self.img_size:(i+2)*self.img_size,(j+1)*self.img_size:(j+2)*self.img_size] = img\n",
    "        \n",
    "        large_img = normalize(large_img)\n",
    "        \n",
    "        self.padding_img = large_img[:,self.img_size-padding:2*self.img_size+padding, self.img_size-padding:2*self.img_size+padding]\n",
    "        self.len = (self.img_size//self.stride)**2\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        row = (index*self.stride // self.img_size)*self.stride\n",
    "        col = (index*self.stride % self.img_size)\n",
    "\n",
    "        img = self.padding_img[:, row:row+self.tile_size, col:col+self.tile_size]        \n",
    "    \n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, fc_nodes=512, num_classes=3, dropout=0.5):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    " \n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:325: SourceChangeWarning: source code of class 'torch.nn.parallel.data_parallel.DataParallel' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:325: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:325: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:325: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "# instatiate the model\n",
    "model = torch.load(MODEL_DIR, map_location=lambda storage, loc: storage)\n",
    "\n",
    "if use_gpu:\n",
    "    model = model.module.cuda()\n",
    "else:\n",
    "    model = model.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [3:24:02<00:00, 405.39s/it]  \n",
      "100%|██████████| 22/22 [2:17:01<00:00, 371.15s/it]  \n",
      "100%|██████████| 30/30 [4:03:55<00:00, 485.01s/it]  \n",
      " 35%|███▍      | 9/26 [47:36<1:30:05, 318.00s/it]"
     ]
    }
   ],
   "source": [
    "for filename in filenames:\n",
    "    TILE_DIR = IMG_DIR+'{}/0/'.format(filename)\n",
    "\n",
    "    imgs = []\n",
    "    for target in sorted(os.listdir(TILE_DIR)):\n",
    "        d = os.path.join(TILE_DIR, target)\n",
    "        if not os.path.isdir(d):\n",
    "            continue\n",
    "\n",
    "        for root, _, fnames in sorted(os.walk(d)):\n",
    "            for fname in sorted(fnames):\n",
    "                if fname.endswith('.jpg'):\n",
    "                    path = os.path.join(root, fname)\n",
    "                    imgs.append(path)\n",
    "\n",
    "    rows = [int(image.split('/')[-2]) for image in imgs]\n",
    "    row_nums = max(rows) + 1\n",
    "    cols = [int(image.split('/')[-1].split('.')[0]) for image in imgs]\n",
    "    col_nums = max(cols) +1    \n",
    "    \n",
    "    heatmap_res = img_size // stride\n",
    "    final_output = np.zeros((3, heatmap_res*row_nums, heatmap_res*col_nums))\n",
    "\n",
    "    model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "    for row in tqdm(range(row_nums)):\n",
    "        for col in range(col_nums):\n",
    "\n",
    "            image_datasets = HeatmapDataset(TILE_DIR, row, col, stride=stride)\n",
    "            dataloader = torch.utils.data.DataLoader(image_datasets, batch_size=batch_size,\n",
    "                                                 shuffle=False, num_workers=num_workers)\n",
    "\n",
    "            running_preds = torch.Tensor(0)\n",
    "            for data in dataloader:\n",
    "                # get the inputs\n",
    "                inputs = data\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    inputs = Variable(inputs.cuda(), volatile=True)\n",
    "                    # forward\n",
    "                    outputs = model(inputs)\n",
    "                    preds = F.sigmoid(outputs) #posibility for each class\n",
    "                    preds = preds.data.cpu()\n",
    "                    running_preds = torch.cat([running_preds, preds])\n",
    "\n",
    "            cored = np.asarray(running_preds[:,0]).reshape(img_size//stride,img_size//stride)\n",
    "            diffuse = np.asarray(running_preds[:,1]).reshape(img_size//stride,img_size//stride)\n",
    "            caa = np.asarray(running_preds[:,2]).reshape(img_size//stride,img_size//stride)\n",
    "\n",
    "            final_output[0, row*heatmap_res:(row+1)*heatmap_res, col*heatmap_res:(col+1)*heatmap_res] = cored\n",
    "            final_output[1, row*heatmap_res:(row+1)*heatmap_res, col*heatmap_res:(col+1)*heatmap_res] = diffuse\n",
    "            final_output[2, row*heatmap_res:(row+1)*heatmap_res, col*heatmap_res:(col+1)*heatmap_res] = caa\n",
    "\n",
    "    np.save(SAVE_DIR+filename, final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(45,15))\n",
    "    \n",
    "ax = fig.add_subplot(311)\n",
    "\n",
    "im = ax.imshow(final_output[0], cmap=plt.cm.get_cmap('viridis', 20), vmin=0, vmax=1)\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "plt.colorbar(im, cax=cax, ticks=[0.0, 0.25, 0.5, 0.75, 1.0])\n",
    "\n",
    "ax = fig.add_subplot(312)\n",
    "\n",
    "im = ax.imshow(final_output[1], cmap=plt.cm.get_cmap('viridis', 20), vmin=0, vmax=1)\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "plt.colorbar(im, cax=cax, ticks=[0.0, 0.25, 0.5, 0.75, 1.0])\n",
    "\n",
    "ax = fig.add_subplot(313)\n",
    "\n",
    "im = ax.imshow(final_output[2], cmap=plt.cm.get_cmap('viridis', 20), vmin=0, vmax=1)\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "plt.colorbar(im, cax=cax, ticks=[0.0, 0.25, 0.5, 0.75, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
