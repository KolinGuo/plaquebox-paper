{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Saliency Mapping - Guided Grad-CAM\n",
    "\n",
    "Guided gradient-weighted class activation mapping (guided Grad-CAM) was performed to generate activation maps (also known as saliency maps) highlighting the features that have a positive influence on the prediction of the class of interest. We adapted the code from [Utku Ozbulak](https://github.com/utkuozbulak/pytorch-cnn-visualizations) to implement guided Grad-CAM. Features that had postive impact on the CNN prediction for each target class were highlighted in bright white.\n",
    "\n",
    "This notebook also includes the implementation of Vanilla backprop, Guided backprop and Grad-CAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(123456789)\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIR = 'data/tiles/hold-out/'\n",
    "MODEL_DIR = 'models/CNN_model_parameters.pkl'\n",
    "SAVE_DIR = 'data/outputs/selected_test_blobs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(SAVE_DIR):\n",
    "        os.makedirs(SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_class = ['cored','diffuse','CAA']\n",
    "norm = np.load('utils/normalization.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv('data/CSVs/selected_test_blobs.csv')\n",
    "image_list = list(file['tilename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def imshow(inp, size=3, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    try:\n",
    "        inp = inp.numpy().transpose((1, 2, 0))\n",
    "    except:\n",
    "        inp = inp.transpose((1, 2, 0))\n",
    "    \n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    fig = plt.figure(figsize=(size,size))\n",
    "    ax = fig.subplots()\n",
    "    try:\n",
    "        ax.imshow(inp)\n",
    "    except:\n",
    "        ax.imshow(inp[:,:,0], cmap='gray')\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    plt.pause(0.001)  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_class_activation_on_image(org_img, activation_map, file_name, save_dir, img_class):\n",
    "    \"\"\"\n",
    "        Saves cam activation map and activation map on the original image\n",
    "    Args:\n",
    "        org_img (PIL img): Original image\n",
    "        activation_map (numpy arr): activation map (grayscale) 0-255\n",
    "        file_name (str): File name of the exported image\n",
    "        save_dir (str): Dir for saving\n",
    "        img_classes (str): target class - cored, diffuse or CAA\n",
    "    \"\"\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    # Grayscale activation map\n",
    "    path_to_file = os.path.join(save_dir, file_name+'_Cam_Grayscale_{}.jpg'.format(img_class))\n",
    "    cv2.imwrite(path_to_file, activation_map)\n",
    "    # Heatmap of activation map\n",
    "    activation_heatmap = cv2.applyColorMap(activation_map, cv2.COLORMAP_HSV)\n",
    "    path_to_file = os.path.join(save_dir, file_name+'_Cam_Heatmap_{}.jpg'.format(img_class))\n",
    "    cv2.imwrite(path_to_file, activation_heatmap)\n",
    "    # Heatmap on picture\n",
    "    img_with_heatmap = np.float32(activation_heatmap) + np.float32(org_img)\n",
    "    img_with_heatmap = img_with_heatmap / np.max(img_with_heatmap)\n",
    "    path_to_file = os.path.join(save_dir, file_name+'_Cam_On_Image_{}.jpg'.format(img_class))\n",
    "    cv2.imwrite(path_to_file, np.uint8(255 * img_with_heatmap))\n",
    "    \n",
    "def get_positive_negative_saliency(gradient):\n",
    "    \"\"\"\n",
    "        Generates positive and negative saliency maps based on the gradient\n",
    "    Args:\n",
    "        gradient (numpy arr): Gradient of the operation to visualize\n",
    "    returns:\n",
    "        pos_saliency ( )\n",
    "    \"\"\"\n",
    "    pos_saliency = (np.maximum(0, gradient) / gradient.max())\n",
    "    neg_saliency = (np.maximum(0, -gradient) / -gradient.min())\n",
    "    return pos_saliency, neg_saliency\n",
    "\n",
    "def convert_to_grayscale(cv2im):\n",
    "    \"\"\"\n",
    "        Converts 3d image to grayscale\n",
    "    Args:\n",
    "        cv2im (numpy arr): RGB image with shape (D,W,H)\n",
    "    returns:\n",
    "        grayscale_im (numpy_arr): Grayscale image with shape (1,W,D)\n",
    "    \"\"\"\n",
    "    grayscale_im = np.sum(np.abs(cv2im), axis=0)\n",
    "    im_max = np.percentile(grayscale_im, 99)\n",
    "    im_min = np.min(grayscale_im)\n",
    "    grayscale_im = (np.clip((grayscale_im - im_min) / (im_max - im_min), 0, 1))\n",
    "    grayscale_im = np.expand_dims(grayscale_im, axis=0)\n",
    "    return grayscale_im\n",
    "\n",
    "def save_gradient_images(gradient, file_name, save_dir, size=3, save=False, show=False):\n",
    "    \"\"\"\n",
    "        Exports the original gradient image\n",
    "    Args:\n",
    "        gradient (np arr): Numpy array of the gradient with shape (3, 224, 224)\n",
    "        file_name (str): File name to be exported\n",
    "        save_dir (str): Dir for saving\n",
    "        size (int): Size for showing\n",
    "        save (bool): Whether save image\n",
    "        show (bool): Whether show image\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    gradient = gradient - gradient.min()\n",
    "    gradient /= gradient.max()\n",
    "    if show:\n",
    "        imshow(gradient, size=size, title=file_name)\n",
    "    gradient = np.uint8(gradient * 255).transpose(1, 2, 0)\n",
    "    path_to_file = os.path.join(save_dir, file_name + '.jpg')\n",
    "    # Convert RBG to GBR\n",
    "    gradient = gradient[..., ::-1]\n",
    "    if save:\n",
    "        cv2.imwrite(path_to_file, gradient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CamExtractor():\n",
    "    \"\"\"\n",
    "        Extracts cam features from the model\n",
    "    \"\"\"\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "\n",
    "    def save_gradient(self, grad):\n",
    "        self.gradients = grad\n",
    "\n",
    "    def forward_pass_on_convolutions(self, x):\n",
    "        \"\"\"\n",
    "            Does a forward pass on convolutions, hooks the function at given layer\n",
    "        \"\"\"\n",
    "        conv_output = None\n",
    "        for module_pos, module in self.model.features._modules.items():\n",
    "            x = module(x)  # Forward\n",
    "            if int(module_pos) == self.target_layer:\n",
    "                x.register_hook(self.save_gradient)\n",
    "                conv_output = x  # Save the convolution output on that layer\n",
    "        return conv_output, x\n",
    "\n",
    "    def forward_pass(self, x):\n",
    "        \"\"\"\n",
    "            Does a full forward pass on the model\n",
    "        \"\"\"\n",
    "        conv_output, x = self.forward_pass_on_convolutions(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.model.classifier(x)\n",
    "        return conv_output, x\n",
    "\n",
    "class GradCam():\n",
    "    \"\"\"\n",
    "        Produces class activation map\n",
    "    \"\"\"\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.extractor = CamExtractor(self.model, target_layer)\n",
    "\n",
    "    def generate_cam(self, input_image, target_class=None):\n",
    "        # Full forward pass\n",
    "        conv_output, model_output = self.extractor.forward_pass(input_image)\n",
    "        if target_class is None:\n",
    "            target_class = np.argmax(model_output.data.numpy())\n",
    "        # Target for backprop\n",
    "        one_hot_output = torch.FloatTensor(1, model_output.size()[-1]).zero_()\n",
    "        one_hot_output[0][target_class] = 1\n",
    "        # Zero grads\n",
    "        self.model.features.zero_grad()\n",
    "        self.model.classifier.zero_grad()\n",
    "        # Backward pass with specified target\n",
    "        model_output.backward(gradient=one_hot_output, retain_graph=True)\n",
    "        # Get hooked gradients\n",
    "        guided_gradients = self.extractor.gradients.data.numpy()[0]\n",
    "        # Get convolution outputs\n",
    "        target = conv_output.data.numpy()[0]\n",
    "        # Get weights from gradients\n",
    "        weights = np.mean(guided_gradients, axis=(1, 2))  # Take averages for each gradient\n",
    "        # Create empty numpy array for cam\n",
    "        cam = np.ones(target.shape[1:], dtype=np.float32)\n",
    "        # Multiply each weight with its conv output and then, sum\n",
    "        for i, w in enumerate(weights):\n",
    "            cam += w * target[i, :, :]\n",
    "        cam = cv2.resize(cam, (256, 256))\n",
    "        cam = np.maximum(cam, 0)\n",
    "        cam = (cam - np.min(cam)) / (np.max(cam) - np.min(cam))  # Normalize between 0-1\n",
    "        cam = np.uint8(cam * 255)  # Scale between 0-255 to visualize\n",
    "        return cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import ReLU\n",
    "\n",
    "class GuidedBackprop():\n",
    "    \"\"\"\n",
    "       Produces gradients generated with guided back propagation from the given image\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.gradients = None\n",
    "        self.model.eval()\n",
    "        self.update_relus()\n",
    "        self.hook_layers()\n",
    "\n",
    "    def hook_layers(self):\n",
    "        def hook_function(module, grad_in, grad_out):\n",
    "            self.gradients = grad_in[0]\n",
    "\n",
    "        # Register hook to the first layer\n",
    "        first_layer = list(self.model.features._modules.items())[0][1]\n",
    "        first_layer.register_backward_hook(hook_function)\n",
    "\n",
    "    def update_relus(self):\n",
    "        \"\"\"\n",
    "            Updates relu activation functions so that it only returns positive gradients\n",
    "        \"\"\"\n",
    "        def relu_hook_function(module, grad_in, grad_out):\n",
    "            \"\"\"\n",
    "            If there is a negative gradient, changes it to zero\n",
    "            \"\"\"\n",
    "            if isinstance(module, ReLU):\n",
    "                return (torch.clamp(grad_in[0], min=0.0),)\n",
    "        # Loop through layers, hook up ReLUs with relu_hook_function\n",
    "        for pos, module in self.model.features._modules.items():\n",
    "            if isinstance(module, ReLU):\n",
    "                module.register_backward_hook(relu_hook_function)\n",
    "\n",
    "    def generate_gradients(self, input_image, target_class):\n",
    "        # Forward pass\n",
    "        model_output = self.model(input_image)\n",
    "        # Zero gradients\n",
    "        self.model.zero_grad()\n",
    "        # Target for backprop\n",
    "        one_hot_output = torch.FloatTensor(1, model_output.size()[-1]).zero_()\n",
    "        one_hot_output[0][target_class] = 1\n",
    "        # Backward pass\n",
    "        model_output.backward(gradient=one_hot_output)\n",
    "        # Convert Pytorch variable to numpy array\n",
    "        gradients_as_arr = self.gradients.data.numpy()[0]\n",
    "        return gradients_as_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaBackprop():\n",
    "    \"\"\"\n",
    "        Produces gradients generated with vanilla back propagation from the image\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.gradients = None\n",
    "        self.model.eval()\n",
    "        # Hook the first layer to get the gradient\n",
    "        self.hook_layers()\n",
    "\n",
    "    def hook_layers(self):\n",
    "        def hook_function(module, grad_in, grad_out):\n",
    "            self.gradients = grad_in[0]\n",
    "\n",
    "        # Register hook to the first layer\n",
    "        first_layer = list(self.model.features._modules.items())[0][1]\n",
    "        first_layer.register_backward_hook(hook_function)\n",
    "\n",
    "    def generate_gradients(self, input_image, target_class):\n",
    "        # Forward\n",
    "        model_output = self.model(input_image)\n",
    "        # Zero grads\n",
    "        self.model.zero_grad()\n",
    "        # Target for backprop\n",
    "        one_hot_output = torch.FloatTensor(1, model_output.size()[-1]).zero_()\n",
    "        one_hot_output[0][target_class] = 1\n",
    "        # Backward pass\n",
    "        model_output.backward(gradient=one_hot_output)\n",
    "        # Convert Pytorch variable to numpy array\n",
    "        gradients_as_arr = self.gradients.data.numpy()[0]\n",
    "        return gradients_as_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guided_grad_cam(grad_cam_mask, guided_backprop_mask):\n",
    "    \"\"\"\n",
    "        Guided grad cam is just pointwise multiplication of cam mask and\n",
    "        guided backprop mask\n",
    "    Args:\n",
    "        grad_cam_mask (np_arr): Class activation map mask\n",
    "        guided_backprop_mask (np_arr):Guided backprop mask\n",
    "    \"\"\"\n",
    "    cam_gb = np.multiply(grad_cam_mask, guided_backprop_mask)\n",
    "    return cam_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, fc_nodes=512, num_classes=3, dropout=0.5):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    " \n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:325: SourceChangeWarning: source code of class 'torch.nn.parallel.data_parallel.DataParallel' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:325: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:325: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:325: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "# instatiate the model and load the model onto the CPU\n",
    "model = torch.load(MODEL_DIR, map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.5) /io/opencv/modules/imgproc/src/color.cpp:181: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-08033e260a9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0moriginal_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMG_DIR\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mimtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(3.4.5) /io/opencv/modules/imgproc/src/color.cpp:181: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "for img in image_list:\n",
    "    \n",
    "    if img is np.nan:\n",
    "        continue\n",
    "        \n",
    "    wsi_name = img.split('/')[0]\n",
    "    source_name = ''.join(img.split('/')[-1].split('.jpg'))\n",
    "    img_name = wsi_name+'/'+source_name+'.jpg'\n",
    "    save_dir = SAVE_DIR+'{}/'.format(source_name)\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    original_image = cv2.imread(IMG_DIR+img_name, 1)\n",
    "    im = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "    im = Image.fromarray(im)    \n",
    "    imtensor = transforms.ToTensor()(im)\n",
    "    imtensor = transforms.Normalize(norm['mean'], norm['std'])(imtensor)\n",
    "    imtensor = imtensor.view(1,3,256,256)\n",
    "    input_img = Variable(imtensor, requires_grad=True)\n",
    "    \n",
    "    for target_class in range(len(img_class)):\n",
    "        # Vanilla backprop\n",
    "        VBP = VanillaBackprop(model.module.cpu())\n",
    "        vanilla_grads = VBP.generate_gradients(input_img, target_class) # 0 for cored\n",
    "        save_gradient_images(vanilla_grads, source_name + '_Vanilla_BP_color_'+img_class[target_class], \n",
    "                             save_dir, save=True)\n",
    "        grayscale_vanilla_grads = convert_to_grayscale(vanilla_grads)\n",
    "        save_gradient_images(grayscale_vanilla_grads, source_name + '_Vanilla_BP_gray_'+img_class[target_class], \n",
    "                             save_dir, save=True)\n",
    "\n",
    "        # Guided backprop\n",
    "        GBP = GuidedBackprop(model.module.cpu())\n",
    "        guided_grads = GBP.generate_gradients(input_img, target_class)\n",
    "        save_gradient_images(guided_grads, source_name + '_Guided_BP_color_'+img_class[target_class],\n",
    "                             save_dir, save=True)\n",
    "        grayscale_guided_grads = convert_to_grayscale(guided_grads)    # Convert to grayscale\n",
    "        save_gradient_images(grayscale_guided_grads, source_name + '_Guided_BP_gray_'+img_class[target_class], \n",
    "                             save_dir, save=True)\n",
    "\n",
    "        # Grad cam\n",
    "        grad_cam = GradCam(model.module.cpu(), target_layer=23)\n",
    "        cam = grad_cam.generate_cam(input_img, target_class)\n",
    "        save_class_activation_on_image(original_image, cam, source_name, save_dir, img_class[target_class])\n",
    "\n",
    "        # Guided Grad cam\n",
    "        gcv2 = GradCam(model.module.cpu(), target_layer=23)\n",
    "        cam = gcv2.generate_cam(input_img, target_class)\n",
    "\n",
    "        GBP = GuidedBackprop(model.module.cpu())\n",
    "        guided_grads = GBP.generate_gradients(input_img, target_class)\n",
    "\n",
    "        cam_gb = guided_grad_cam(cam, guided_grads)\n",
    "        save_gradient_images(cam_gb, source_name + '_GGrad_Cam_'+img_class[target_class], \n",
    "                             save_dir, save=True)\n",
    "        grayscale_cam_gb = convert_to_grayscale(cam_gb)\n",
    "        save_gradient_images(grayscale_cam_gb, source_name + '_GGrad_Cam_gray_'+img_class[target_class], \n",
    "                             save_dir, save=True)\n",
    "\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
